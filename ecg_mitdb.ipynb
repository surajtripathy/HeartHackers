{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U8PLq6nIR3Ut",
        "outputId": "8489b576-0ddd-49ef-d826-7e20d6e911d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: wfdb in /usr/local/lib/python3.8/dist-packages (4.1.0)\n",
            "Requirement already satisfied: scipy<2.0.0,>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from wfdb) (1.10.1)\n",
            "Requirement already satisfied: pandas<2.0.0,>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from wfdb) (1.3.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.8.1 in /usr/local/lib/python3.8/dist-packages (from wfdb) (2.25.1)\n",
            "Requirement already satisfied: matplotlib<4.0.0,>=3.2.2 in /usr/local/lib/python3.8/dist-packages (from wfdb) (3.5.3)\n",
            "Requirement already satisfied: SoundFile<0.12.0,>=0.10.0 in /usr/local/lib/python3.8/dist-packages (from wfdb) (0.11.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.10.1 in /usr/local/lib/python3.8/dist-packages (from wfdb) (1.22.4)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib<4.0.0,>=3.2.2->wfdb) (8.4.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib<4.0.0,>=3.2.2->wfdb) (23.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib<4.0.0,>=3.2.2->wfdb) (4.38.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib<4.0.0,>=3.2.2->wfdb) (0.11.0)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib<4.0.0,>=3.2.2->wfdb) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib<4.0.0,>=3.2.2->wfdb) (1.4.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.8/dist-packages (from matplotlib<4.0.0,>=3.2.2->wfdb) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas<2.0.0,>=1.0.0->wfdb) (2022.7.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.8.1->wfdb) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.8.1->wfdb) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.8.1->wfdb) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.8.1->wfdb) (1.26.14)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.8/dist-packages (from SoundFile<0.12.0,>=0.10.0->wfdb) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.8/dist-packages (from cffi>=1.0->SoundFile<0.12.0,>=0.10.0->wfdb) (2.21)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7->matplotlib<4.0.0,>=3.2.2->wfdb) (1.15.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install wfdb"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "import os\n",
        "os.chdir('/content/gdrive/MyDrive/ECG_Classification_Pytorch-master/raw_data')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oWtA13bvSI17",
        "outputId": "7ec30f9b-7c13-4937-de33-97f2a26053cc"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "import wfdb\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "VSubniezR4k6"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ecg_record = wfdb.rdrecord('14046', channels= [0])\n",
        "# ecg_record.fs "
      ],
      "metadata": {
        "id": "-oRzRlkyR-IM"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ecg_record = wfdb.rdrecord('14046', sampfrom= 0, sampto= 108300, channels= [1])"
      ],
      "metadata": {
        "id": "sCobEx0qSZx1"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ecg = ecg_record.p_signal[:,0]\n",
        "train_len = 108000\n",
        "\n",
        "ecg_train = ecg[0: train_len]\n",
        "ecg_test = ecg[train_len:]"
      ],
      "metadata": {
        "id": "Q3n6qBsdUZ6o"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ecg_train = torch.FloatTensor(ecg_train).view(-1)"
      ],
      "metadata": {
        "id": "-ClMp60PUic3"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ecg_test = torch.FloatTensor(ecg_test).view(-1)"
      ],
      "metadata": {
        "id": "uxWbnmCgUjM_"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_inout_sequences(input_data, tw):\n",
        "    inout_seq = []\n",
        "    L = len(input_data)\n",
        "    for i in range(L-tw):\n",
        "        train_seq = input_data[i:i+tw]\n",
        "        train_label = input_data[i+tw:i+tw+1]\n",
        "        inout_seq.append((train_seq ,train_label))\n",
        "    return inout_seq   "
      ],
      "metadata": {
        "id": "6KzGyiWqVC8i"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def create_dataloader(data_entered, train_window, batch_size):\n",
        "  data = create_inout_sequences(data_entered, train_window)\n",
        "  data_loader = torch.utils.data.DataLoader(data,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=True, drop_last= True)\n",
        "  return data_loader\n",
        "\n"
      ],
      "metadata": {
        "id": "6nM6vBg_Zi8O"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "train_window = 850  # 3 cardiac cycles in each sequence\n",
        "# train_data = create_inout_sequences(ecg_train, train_window)\n",
        "batch_size = 64\n",
        "\n"
      ],
      "metadata": {
        "id": "wYc8vHAyZlBG"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTM(nn.Module):\n",
        "    def __init__(self, input_size=1, hidden_dim=100, n_layers=5, output_size=1, drop_prob=0.5, lr=0.001):\n",
        "        super().__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.n_layers = n_layers\n",
        "        self.drop_prob = drop_prob\n",
        "        self.lr = lr\n",
        "\n",
        "        ## define the LSTM\n",
        "        self.lstm = nn.LSTM(input_size, hidden_dim, num_layers= n_layers, dropout=drop_prob, batch_first=True)\n",
        "        \n",
        "        ## define a dropout layer\n",
        "        self.dropout = nn.Dropout(drop_prob)\n",
        "\n",
        "        ## define the final, fully-connected output layer\n",
        "        self.linear = nn.Linear(hidden_dim, output_size)\n",
        "\n",
        "\n",
        "    def forward(self, input_seq, hidden):\n",
        "        lstm_out, hidden = self.lstm(input_seq, hidden)\n",
        "        out = self.dropout(lstm_out)\n",
        "        out = out.contiguous().view(-1, self.hidden_dim)\n",
        "\n",
        "        #fully-connected layer\n",
        "        out = self.linear(out)\n",
        "\n",
        "        batch_size = input_seq.size(0)\n",
        "        \n",
        "        # return the final output and the hidden state\n",
        "        return out, hidden\n",
        "\n",
        "    def init_hidden(self, batch_size):\n",
        "        ''' Initializes hidden state '''\n",
        "        # Create two new tensors with sizes n_layers x batch_size x n_hidden,\n",
        "        # initialized to zero, for hidden state and cell state of LSTM\n",
        "        weight = next(self.parameters()).data\n",
        "        \n",
        "        if (train_on_gpu):\n",
        "            hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda(),\n",
        "                  weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda())\n",
        "        else:\n",
        "            hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_(),\n",
        "                      weight.new(self.n_layers, batch_size, self.hidden_dim).zero_())\n",
        "        \n",
        "        return hidden"
      ],
      "metadata": {
        "id": "JUPBoD_3ZmmC"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ecg_val = wfdb.rdrecord('14046', sampfrom= 108300, sampto= 129900, channels= [0])\n",
        "ecg_val = ecg_val.p_signal[:,0]\n",
        "\n",
        "wfdb.plot_items(ecg_val)\n",
        "ecg_val = torch.FloatTensor(ecg_val).view(-1)\n",
        "\n",
        "seq_length = train_window\n",
        "train_data_loader = create_dataloader(ecg_train, seq_length, batch_size)\n",
        "val_data_loader = create_dataloader(ecg_val, seq_length, batch_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "xJx7B99iZpcg",
        "outputId": "c8f21232-9f82-4bff-a256-adbc32a71f7b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train(net, train_data_loader, val_data_loader, epochs=20, batch_size=batch_size, lr=0.1, clip=5, print_every=10):\n",
        "    ''' Training a network \n",
        "    \n",
        "        Arguments\n",
        "        ---------\n",
        "        \n",
        "        net: LSTM network\n",
        "        data: ecg data to train the network\n",
        "        epochs: Number of epochs to train\n",
        "        batch_size: Number of mini-sequences per mini-batch, aka batch size\n",
        "        seq_length: Number of character steps per mini-batch\n",
        "        lr: learning rate\n",
        "        clip: gradient clipping\n",
        "        val_frac: Fraction of data to hold out for validation\n",
        "        print_every: Number of steps for printing training and validation loss\n",
        "    \n",
        "    '''\n",
        "    net.train()\n",
        "    \n",
        "    opt = torch.optim.Adam(net.parameters(), lr=lr)\n",
        "    criterion = nn.L1Loss()\n",
        "    \n",
        "    if(train_on_gpu):\n",
        "        net.cuda()\n",
        "    \n",
        "    counter = 0\n",
        "    for e in range(epochs):\n",
        "        # initialize hidden state\n",
        "        h = net.init_hidden(batch_size)\n",
        "        \n",
        "        for x, y in train_data_loader:\n",
        "            counter += 1\n",
        "            x = torch.unsqueeze(x, 2)\n",
        "\n",
        "            inputs, targets = x, y\n",
        "            \n",
        "            if(train_on_gpu):\n",
        "                inputs, targets = inputs.cuda(), targets.cuda()\n",
        "\n",
        "            # Creating new variables for the hidden state, otherwise\n",
        "            # we'd backprop through the entire training history\n",
        "            h = tuple([each.data for each in h])\n",
        "\n",
        "            # zero accumulated gradients\n",
        "            net.zero_grad()\n",
        "            \n",
        "            # get the output from the model\n",
        "            output, h = net(inputs, h)\n",
        "            \n",
        "            # calculate the loss and perform backprop\n",
        "            loss = criterion(output, targets.view(batch_size).long())\n",
        "            loss.backward()\n",
        "            # `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n",
        "            nn.utils.clip_grad_norm_(net.parameters(), clip)\n",
        "            opt.step()\n",
        "            \n",
        "            # loss stats\n",
        "            if counter % print_every == 0:\n",
        "                # Get validation loss\n",
        "                val_h = net.init_hidden(batch_size)\n",
        "                val_losses = []\n",
        "                net.eval()\n",
        "                for x, y in val_data_loader:\n",
        "                    # Creating new variables for the hidden state, otherwise\n",
        "                    # we'd backprop through the entire training history\n",
        "                    val_h = tuple([each.data for each in val_h])\n",
        "\n",
        "                    x = torch.unsqueeze(x, 2)\n",
        "\n",
        "                    inputs, targets = x, y\n",
        "                    if(train_on_gpu):\n",
        "                        inputs, targets = inputs.cuda(), targets.cuda()\n",
        "\n",
        "                    output, val_h = net(inputs, val_h)\n",
        "                    val_loss = criterion(output, targets.view(batch_size).long())\n",
        "                \n",
        "                    val_losses.append(val_loss.item())\n",
        "                \n",
        "                net.train() # reset to train mode\n",
        "                \n",
        "                print(\"Epoch: {}/{}...\".format(e+1, epochs),\n",
        "                      \"Step: {}...\".format(counter),\n",
        "                      \"Loss: {:.4f}...\".format(loss.item()),\n",
        "                      \"Val Loss: {:.4f}\".format(np.mean(val_losses)))"
      ],
      "metadata": {
        "id": "JiOnKvAwZrXh"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hidden_dim=32\n",
        "n_layers=3\n",
        "\n",
        "net = LSTM(hidden_dim= hidden_dim, n_layers= n_layers)\n",
        "print(net)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gVCdJjJSZ01Q",
        "outputId": "661b0025-5d10-4e36-85f8-d93b66faebd0"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LSTM(\n",
            "  (lstm): LSTM(1, 32, num_layers=3, batch_first=True, dropout=0.5)\n",
            "  (dropout): Dropout(p=0.5, inplace=False)\n",
            "  (linear): Linear(in_features=32, out_features=1, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_on_gpu = torch.cuda.is_available()"
      ],
      "metadata": {
        "id": "FrIdVzbCZ2PR"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "seq_length = train_window\n",
        "n_epochs = 1\n",
        "\n",
        "# model training\n",
        "# train(net, ecg_train, epochs=n_epochs, batch_size=batch_size, seq_length=seq_length, lr=0.001, print_every=10)\n",
        "\n",
        "train(net, train_data_loader, val_data_loader, epochs=n_epochs, batch_size=batch_size, lr=0.25, print_every=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xm9mH8lvZ4ny",
        "outputId": "bf0cc356-8f35-414a-da8c-868e4d7e38b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1/1... Step: 10... Loss: 1.6030... Val Loss: 0.5116\n",
            "Epoch: 1/1... Step: 20... Loss: 0.7654... Val Loss: 0.3311\n",
            "Epoch: 1/1... Step: 30... Loss: 0.4135... Val Loss: 0.4355\n",
            "Epoch: 1/1... Step: 40... Loss: 0.2582... Val Loss: 0.2965\n",
            "Epoch: 1/1... Step: 50... Loss: 0.5618... Val Loss: 0.2502\n",
            "Epoch: 1/1... Step: 60... Loss: 0.5954... Val Loss: 0.2096\n",
            "Epoch: 1/1... Step: 70... Loss: 0.4923... Val Loss: 0.3055\n",
            "Epoch: 1/1... Step: 80... Loss: 0.7286... Val Loss: 0.4846\n",
            "Epoch: 1/1... Step: 90... Loss: 0.3181... Val Loss: 0.3205\n",
            "Epoch: 1/1... Step: 100... Loss: 0.4385... Val Loss: 0.1352\n",
            "Epoch: 1/1... Step: 110... Loss: 0.9196... Val Loss: 0.4907\n",
            "Epoch: 1/1... Step: 120... Loss: 0.3138... Val Loss: 0.4095\n",
            "Epoch: 1/1... Step: 130... Loss: 0.4547... Val Loss: 0.5106\n",
            "Epoch: 1/1... Step: 140... Loss: 1.2186... Val Loss: 0.8091\n",
            "Epoch: 1/1... Step: 150... Loss: 0.4787... Val Loss: 0.5484\n",
            "Epoch: 1/1... Step: 160... Loss: 0.2673... Val Loss: 0.1728\n",
            "Epoch: 1/1... Step: 170... Loss: 0.3021... Val Loss: 0.2758\n",
            "Epoch: 1/1... Step: 180... Loss: 0.2024... Val Loss: 0.2950\n",
            "Epoch: 1/1... Step: 190... Loss: 0.5677... Val Loss: 0.5619\n",
            "Epoch: 1/1... Step: 200... Loss: 0.2722... Val Loss: 0.3651\n",
            "Epoch: 1/1... Step: 210... Loss: 0.4100... Val Loss: 0.1251\n",
            "Epoch: 1/1... Step: 220... Loss: 0.5987... Val Loss: 0.7761\n",
            "Epoch: 1/1... Step: 230... Loss: 0.6568... Val Loss: 0.3237\n",
            "Epoch: 1/1... Step: 240... Loss: 0.3997... Val Loss: 0.3715\n",
            "Epoch: 1/1... Step: 250... Loss: 0.2774... Val Loss: 0.1430\n",
            "Epoch: 1/1... Step: 260... Loss: 0.6205... Val Loss: 0.7322\n",
            "Epoch: 1/1... Step: 270... Loss: 1.3086... Val Loss: 0.9566\n",
            "Epoch: 1/1... Step: 280... Loss: 0.5116... Val Loss: 0.4604\n",
            "Epoch: 1/1... Step: 290... Loss: 0.6775... Val Loss: 0.8935\n",
            "Epoch: 1/1... Step: 300... Loss: 1.1264... Val Loss: 0.7685\n",
            "Epoch: 1/1... Step: 310... Loss: 1.3934... Val Loss: 1.1676\n",
            "Epoch: 1/1... Step: 320... Loss: 0.2226... Val Loss: 0.6373\n",
            "Epoch: 1/1... Step: 330... Loss: 0.8867... Val Loss: 0.8612\n",
            "Epoch: 1/1... Step: 340... Loss: 0.9072... Val Loss: 0.7074\n",
            "Epoch: 1/1... Step: 350... Loss: 0.3598... Val Loss: 0.4027\n",
            "Epoch: 1/1... Step: 360... Loss: 0.7284... Val Loss: 0.9514\n",
            "Epoch: 1/1... Step: 370... Loss: 0.3450... Val Loss: 0.4346\n",
            "Epoch: 1/1... Step: 380... Loss: 0.3650... Val Loss: 0.1585\n",
            "Epoch: 1/1... Step: 390... Loss: 0.4611... Val Loss: 0.0859\n",
            "Epoch: 1/1... Step: 400... Loss: 0.3088... Val Loss: 0.2857\n",
            "Epoch: 1/1... Step: 410... Loss: 0.5813... Val Loss: 0.2547\n",
            "Epoch: 1/1... Step: 420... Loss: 0.8326... Val Loss: 0.6187\n",
            "Epoch: 1/1... Step: 430... Loss: 1.0482... Val Loss: 0.5397\n",
            "Epoch: 1/1... Step: 440... Loss: 0.6579... Val Loss: 0.4171\n",
            "Epoch: 1/1... Step: 450... Loss: 0.1920... Val Loss: 0.3526\n",
            "Epoch: 1/1... Step: 460... Loss: 0.2523... Val Loss: 0.3200\n",
            "Epoch: 1/1... Step: 470... Loss: 0.4664... Val Loss: 0.0903\n",
            "Epoch: 1/1... Step: 480... Loss: 0.3585... Val Loss: 0.2967\n",
            "Epoch: 1/1... Step: 490... Loss: 0.2265... Val Loss: 0.1463\n",
            "Epoch: 1/1... Step: 500... Loss: 0.2594... Val Loss: 0.4042\n",
            "Epoch: 1/1... Step: 510... Loss: 0.2425... Val Loss: 0.1490\n",
            "Epoch: 1/1... Step: 520... Loss: 0.1047... Val Loss: 0.3203\n",
            "Epoch: 1/1... Step: 530... Loss: 0.4857... Val Loss: 0.1329\n",
            "Epoch: 1/1... Step: 540... Loss: 0.3516... Val Loss: 0.2308\n",
            "Epoch: 1/1... Step: 550... Loss: 0.2610... Val Loss: 0.3069\n",
            "Epoch: 1/1... Step: 560... Loss: 0.3738... Val Loss: 0.1953\n",
            "Epoch: 1/1... Step: 570... Loss: 0.7350... Val Loss: 0.2421\n",
            "Epoch: 1/1... Step: 580... Loss: 0.7183... Val Loss: 0.4655\n",
            "Epoch: 1/1... Step: 590... Loss: 0.5647... Val Loss: 0.4292\n",
            "Epoch: 1/1... Step: 600... Loss: 0.2181... Val Loss: 0.2903\n",
            "Epoch: 1/1... Step: 610... Loss: 0.5005... Val Loss: 0.2983\n",
            "Epoch: 1/1... Step: 620... Loss: 0.7844... Val Loss: 1.1242\n",
            "Epoch: 1/1... Step: 630... Loss: 0.7321... Val Loss: 1.1972\n",
            "Epoch: 1/1... Step: 640... Loss: 0.8268... Val Loss: 0.7333\n",
            "Epoch: 1/1... Step: 650... Loss: 0.8179... Val Loss: 0.2011\n",
            "Epoch: 1/1... Step: 660... Loss: 1.5094... Val Loss: 0.9250\n",
            "Epoch: 1/1... Step: 670... Loss: 1.7135... Val Loss: 2.0072\n",
            "Epoch: 1/1... Step: 680... Loss: 0.6745... Val Loss: 1.1588\n",
            "Epoch: 1/1... Step: 690... Loss: 0.8756... Val Loss: 1.2888\n",
            "Epoch: 1/1... Step: 700... Loss: 0.3261... Val Loss: 0.2438\n",
            "Epoch: 1/1... Step: 710... Loss: 0.5247... Val Loss: 0.0940\n",
            "Epoch: 1/1... Step: 720... Loss: 0.7713... Val Loss: 0.4198\n",
            "Epoch: 1/1... Step: 730... Loss: 0.6343... Val Loss: 0.2604\n",
            "Epoch: 1/1... Step: 740... Loss: 0.7517... Val Loss: 0.7943\n",
            "Epoch: 1/1... Step: 750... Loss: 1.1336... Val Loss: 0.9079\n",
            "Epoch: 1/1... Step: 760... Loss: 0.4361... Val Loss: 0.7669\n",
            "Epoch: 1/1... Step: 770... Loss: 0.3288... Val Loss: 0.4031\n",
            "Epoch: 1/1... Step: 780... Loss: 0.4117... Val Loss: 0.0873\n",
            "Epoch: 1/1... Step: 790... Loss: 0.3241... Val Loss: 0.1654\n",
            "Epoch: 1/1... Step: 800... Loss: 0.4833... Val Loss: 0.5843\n",
            "Epoch: 1/1... Step: 810... Loss: 0.4262... Val Loss: 0.2490\n",
            "Epoch: 1/1... Step: 820... Loss: 0.2935... Val Loss: 0.2752\n",
            "Epoch: 1/1... Step: 830... Loss: 0.3948... Val Loss: 0.1284\n",
            "Epoch: 1/1... Step: 840... Loss: 0.1855... Val Loss: 0.4038\n",
            "Epoch: 1/1... Step: 850... Loss: 0.2263... Val Loss: 0.7183\n",
            "Epoch: 1/1... Step: 860... Loss: 0.4202... Val Loss: 0.2063\n",
            "Epoch: 1/1... Step: 870... Loss: 0.4752... Val Loss: 0.2774\n",
            "Epoch: 1/1... Step: 880... Loss: 0.5105... Val Loss: 0.3677\n",
            "Epoch: 1/1... Step: 890... Loss: 0.3090... Val Loss: 0.1601\n",
            "Epoch: 1/1... Step: 900... Loss: 0.2990... Val Loss: 0.2794\n",
            "Epoch: 1/1... Step: 910... Loss: 0.5813... Val Loss: 0.5755\n",
            "Epoch: 1/1... Step: 920... Loss: 0.9793... Val Loss: 0.6699\n",
            "Epoch: 1/1... Step: 930... Loss: 0.9211... Val Loss: 0.2467\n",
            "Epoch: 1/1... Step: 940... Loss: 0.1937... Val Loss: 0.6783\n",
            "Epoch: 1/1... Step: 950... Loss: 0.6910... Val Loss: 0.2774\n",
            "Epoch: 1/1... Step: 960... Loss: 0.3926... Val Loss: 0.3760\n",
            "Epoch: 1/1... Step: 970... Loss: 0.1711... Val Loss: 0.3476\n",
            "Epoch: 1/1... Step: 980... Loss: 0.5669... Val Loss: 0.1080\n",
            "Epoch: 1/1... Step: 990... Loss: 0.3346... Val Loss: 0.1977\n",
            "Epoch: 1/1... Step: 1000... Loss: 0.4743... Val Loss: 0.3934\n",
            "Epoch: 1/1... Step: 1010... Loss: 0.4498... Val Loss: 0.5106\n",
            "Epoch: 1/1... Step: 1020... Loss: 0.2472... Val Loss: 0.1469\n",
            "Epoch: 1/1... Step: 1030... Loss: 0.3852... Val Loss: 0.2320\n",
            "Epoch: 1/1... Step: 1040... Loss: 0.2903... Val Loss: 0.4457\n",
            "Epoch: 1/1... Step: 1050... Loss: 0.5394... Val Loss: 0.1554\n",
            "Epoch: 1/1... Step: 1060... Loss: 0.4481... Val Loss: 0.2079\n",
            "Epoch: 1/1... Step: 1070... Loss: 0.6049... Val Loss: 0.6582\n",
            "Epoch: 1/1... Step: 1080... Loss: 0.8633... Val Loss: 0.6926\n",
            "Epoch: 1/1... Step: 1090... Loss: 0.9239... Val Loss: 0.3039\n",
            "Epoch: 1/1... Step: 1100... Loss: 1.4798... Val Loss: 0.9983\n",
            "Epoch: 1/1... Step: 1110... Loss: 1.0081... Val Loss: 0.7262\n",
            "Epoch: 1/1... Step: 1120... Loss: 0.0900... Val Loss: 0.4467\n",
            "Epoch: 1/1... Step: 1130... Loss: 0.7441... Val Loss: 0.0972\n",
            "Epoch: 1/1... Step: 1140... Loss: 0.5167... Val Loss: 0.0931\n",
            "Epoch: 1/1... Step: 1150... Loss: 0.6436... Val Loss: 0.2857\n",
            "Epoch: 1/1... Step: 1160... Loss: 0.3365... Val Loss: 0.0903\n",
            "Epoch: 1/1... Step: 1170... Loss: 0.4050... Val Loss: 0.4703\n",
            "Epoch: 1/1... Step: 1180... Loss: 0.5761... Val Loss: 0.2603\n",
            "Epoch: 1/1... Step: 1190... Loss: 0.7821... Val Loss: 0.2941\n",
            "Epoch: 1/1... Step: 1200... Loss: 0.4238... Val Loss: 0.3099\n",
            "Epoch: 1/1... Step: 1210... Loss: 0.3886... Val Loss: 0.2738\n",
            "Epoch: 1/1... Step: 1220... Loss: 0.3910... Val Loss: 0.2373\n",
            "Epoch: 1/1... Step: 1230... Loss: 0.6999... Val Loss: 0.2911\n",
            "Epoch: 1/1... Step: 1240... Loss: 0.5283... Val Loss: 0.1926\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = 'rnn_10_epoch.net'\n",
        "\n",
        "checkpoint_20E = {'n_hidden': net.hidden_dim,\n",
        "              'n_layers': net.n_layers,\n",
        "              'state_dict': net.state_dict()}\n",
        "\n",
        "with open(model_name, 'wb') as f:\n",
        "    torch.save(checkpoint_20E, f)"
      ],
      "metadata": {
        "id": "h3d7jYP2Z6k1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "n7lZzcsIg1Xs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}